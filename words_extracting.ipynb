{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser, ArgumentTypeError\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from config import Config\n",
    "from interactive_predict import InteractivePredictor\n",
    "from model import Model\n",
    "import reader\n",
    "\n",
    "MODELS_PATH = './models/java-small-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--sparse_subtoken'], dest='sparse_subtoken', nargs=None, const=None, default=True, type=<function str2bool at 0x7fe3a7742440>, choices=None, help='Flag responcing for SUBTOKEN_VOCAB embeddings sparsification', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-d\", \"--data\", dest=\"data_path\",\n",
    "                    help=\"path to preprocessed dataset\", required=False)\n",
    "parser.add_argument(\"-te\", \"--test\", dest=\"test_path\",\n",
    "                    help=\"path to test file\", metavar=\"FILE\", required=False)\n",
    "\n",
    "parser.add_argument(\"-s\", \"--save_prefix\", dest=\"save_path_prefix\",\n",
    "                    help=\"path to save file\", metavar=\"FILE\", required=False)\n",
    "parser.add_argument(\"-l\", \"--load\", dest=\"load_path\",\n",
    "                    help=\"path to saved file\", metavar=\"FILE\", required=False)\n",
    "parser.add_argument('--release', action='store_true',\n",
    "                    help='if specified and loading a trained model, release the loaded model for a smaller model'\n",
    "                         'size.')\n",
    "\n",
    "parser.add_argument('--predict', action='store_true')\n",
    "parser.add_argument('--debug', action='store_true')\n",
    "parser.add_argument('--seed', type=int, default=239)\n",
    "\n",
    "parser.add_argument('--lasso', action='store', default=0, type=float, help='L1-regularisation on embeddings layer coefficient')\n",
    "parser.add_argument('--grouplasso', action='store', default=0, type=float, help='Group Lasso regularisation on embeddings layer coefficient')\n",
    "parser.add_argument('--threshold', action='store', default=-1, type=float, help='Threshold applying for reseting values of tensors to zeros')\n",
    "\n",
    "parser.add_argument('--subtoken_words', action='store', default=190000, type=int, help='SUBTOKEN_VOCAB words max number restriction')\n",
    "parser.add_argument('--nodes_words', action='store', default=-1, type=int, help='NODES_VOCAB words max number restriction')\n",
    "parser.add_argument('--sparse_nodes', type=str2bool, default=True,  help=\"Flag responcing for NODES_VOCAB embeddings sparsification\")\n",
    "parser.add_argument('--sparse_subtoken', type=str2bool, default=True,  help=\"Flag responcing for SUBTOKEN_VOCAB embeddings sparsification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 55\n",
    "folder = '2020_05_02__1e-05_0.0001_0.01__bedfb2fa'\n",
    "\n",
    "dataset_name = 'java-small'\n",
    "data_dir = 'data/java-small'\n",
    "data = f'{data_dir}/{dataset_name}'\n",
    "\n",
    "test_data= f'{data_dir}/{dataset_name}.val.c2s'\n",
    "\n",
    "args = parser.parse_args(['--load', f'{MODELS_PATH}/{folder}/model_iter{epoch}',\n",
    "                          '--data', f'{data}',\n",
    "                          '--test', f'{test_data}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionaries from: ./models/java-small-model/2020_05_02__1e-05_0.0001_0.01__bedfb2fa/model_iter55\n",
      "Done loading dictionaries\n",
      "Created model\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/aagusev2/vocabularyForSourceCode/code2seq/reader.py:101: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/aagusev2/vocabularyForSourceCode/code2seq/reader.py:161: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/aagusev2/vocabularyForSourceCode/code2seq/model.py:424: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
      "Instructions for updating:\n",
      "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "```python\n",
      "    sess = tf.Session()\n",
      "    with sess.as_default():\n",
      "        tensor = tf.range(10)\n",
      "        print_op = tf.print(tensor)\n",
      "        with tf.control_dependencies([print_op]):\n",
      "          out = tf.add(tensor, tensor)\n",
      "        sess.run(out)\n",
      "    ```\n",
      "Additionally, to use tf.print in python 2.7, users must make sure to import\n",
      "the following:\n",
      "\n",
      "  `from __future__ import print_function`\n",
      "\n",
      "WARNING:tensorflow:From /home/aagusev2/vocabularyForSourceCode/code2seq/model.py:548: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/aagusev2/vocabularyForSourceCode/code2seq/model.py:560: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/aagusev2/vocabularyForSourceCode/code2seq/model.py:607: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/aagusev2/vocabularyForSourceCode/code2seq/model.py:474: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "Initalized variables\n",
      "WARNING:tensorflow:From /home/aagusev2/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./models/java-small-model/2020_05_02__1e-05_0.0001_0.01__bedfb2fa/model_iter55\n",
      "Done loading model\n",
      "0\n",
      "[1.2517575 1.4150763 2.4530087 ... 1.336964  1.2531607 1.2962277]\n",
      "Training batch size:                               512\n",
      "Dataset path:                                      data/java-small/java-small\n",
      "Training file path:                                data/java-small/java-small.train.c2s\n",
      "Validation path                                    data/java-small/java-small.val.c2s\n",
      "Taking max contexts from each example:             200\n",
      "Random path sampling:                              True\n",
      "Embedding size:                                    128\n",
      "Using BiLSTMs, each of size:                       128\n",
      "Decoder size:                                      320\n",
      "Decoder layers:                                    1\n",
      "Max path lengths:                                  9\n",
      "Max subtokens in a token:                          5\n",
      "Max target length:                                 6\n",
      "Embeddings dropout keep_prob:                      0.75\n",
      "LSTM dropout keep_prob:                            0.5\n",
      "---------Sparsification parameters----------\n",
      "Lasso coefficient:                                 0\n",
      "Group Lasso coefficient:                           0\n",
      "Threshold for reseting to zeros                    -1\n",
      "NODES_VOCAB sparsisication flag                    True\n",
      "SUBTOKEN_VOCAB sparsisication flag                 True\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "if args.nodes_words == -1:\n",
    "    args.nodes_words = None\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "tf.set_random_seed(args.seed)\n",
    "\n",
    "config = Config.get_default_config(args)\n",
    "\n",
    "model = Model(config)\n",
    "print('Created model')\n",
    "\n",
    "\n",
    "model.queue_thread = reader.Reader(subtoken_to_index=model.subtoken_to_index,\n",
    "                                  node_to_index=model.node_to_index,\n",
    "                                  target_to_index=model.target_to_index,\n",
    "                                  config=model.config)\n",
    "\n",
    "optimizer, train_loss, print_node = model.build_training_graph(model.queue_thread.get_output())\n",
    "model.initialize_session_variables(model.sess)\n",
    "print('Initalized variables')\n",
    "if model.config.LOAD_PATH:\n",
    "    model.load_model(model.sess)\n",
    "\n",
    "    vocab = [v for v in tf.global_variables() if v.name == \"model/SUBTOKENS_VOCAB:0\"][0]\n",
    "    vocab_np = vocab.eval(session=model.sess)\n",
    "    \n",
    "    vocab_rows = np.sum(np.abs(vocab_np), axis=1)\n",
    "    print(vocab_rows[vocab_rows == 0].size)\n",
    "    print(vocab_rows)\n",
    "    \n",
    "model.print_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
